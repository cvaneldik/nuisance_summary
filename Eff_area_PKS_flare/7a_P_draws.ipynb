{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c102068e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gammapy version: 0.1.dev19174+g56b5bdf \n",
      "Supposed to be 1.0 (21-12-2022)\n"
     ]
    }
   ],
   "source": [
    "import gammapy \n",
    "import pyximport\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import sys\n",
    "from gammapy.modeling import Fit, Parameter, Parameters\n",
    "from gammapy.modeling.models import Models\n",
    "from gammapy.maps import MapAxis\n",
    "from gammapy.modeling.models.spectral import scale_plot_flux\n",
    "from gammapy.estimators import  FluxPointsEstimator\n",
    "from gammapy.modeling.models import IRFModels, EffAreaIRFModel\n",
    "    \n",
    "sys.path.append('/home/katrin/Documents/nuisance_summary/')\n",
    "sys.path.append('../') \n",
    "from Dataset_Creation import sys_dataset   # noqa: E402\n",
    "import Dataset_load  # noqa: E402\n",
    "\n",
    "\n",
    "pyximport.install()\n",
    "\n",
    "print(f'loaded gammapy version: {gammapy.__version__} ' )\n",
    "print('Supposed to be 1.0 (21-12-2022)' )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaled_amplitude = Parameter('amplitude',\n",
    "                             value = 1e-12)\n",
    "dataset_asimov  = Dataset_load.create_asimov(model = 'pl', source = \"PKSflare\",\n",
    "                                            parameters = Parameters([scaled_amplitude]))\n",
    "\n",
    "mask = dataset_asimov.mask.data.sum(axis=2).sum(axis=1)>0\n",
    "\n",
    "ebins = dataset_asimov.counts.geom.axes[0].center[mask]\n",
    "print(len(ebins))\n",
    "\n",
    "\n",
    "shift = +0.1\n",
    "tilt = 0.02\n",
    "\n",
    "\n",
    "N = 500\n",
    "sigma_a = shift\n",
    "sigma_i = tilt\n",
    "\n",
    "save = True\n",
    "save_flux = True\n",
    "save_fluxpoints = True\n",
    "save_fluxpoints_N = True\n",
    "dataset_N = True\n",
    "\n",
    "\n",
    "for n in range(N):\n",
    "    print()\n",
    "    print('====' * 30)\n",
    "    print(n)\n",
    "    print('====' * 30)\n",
    "    \n",
    "    shift_rnd = np.random.normal(0, shift, 1)\n",
    "    tilt_rnd = np.random.normal(0, tilt, 1)\n",
    "    print(f\"shift:, {shift_rnd}, tilt: {tilt_rnd}\" )\n",
    "    sys_d_cor = sys_dataset(dataset_asimov= dataset_asimov,\n",
    "                    shift = shift_rnd, \n",
    "                    tilt = tilt_rnd,\n",
    "                    rnd = True)\n",
    "    dataset = sys_d_cor.create_dataset()\n",
    "    fit_cor = Fit(store_trace=False)\n",
    "    minuit_opts = {\"tol\": 0.001, \"strategy\": 2}\n",
    "    fit_cor.optimize_opts = minuit_opts\n",
    "    result_cor = fit_cor.run([dataset])\n",
    "\n",
    "\n",
    "    if save:\n",
    "        with open(\"data/7a_P_draw_info.txt\", \"a\") as myfile:\n",
    "            myfile.write(str(float(shift_rnd)) + '    '+ str(float(tilt_rnd)) + '    ' +  str(float(dataset.stat_sum())) + '\\n')\n",
    "\n",
    "    stri = \"\"\n",
    "    for p in ['amplitude', 'index', 'norm', 'tilt']:\n",
    "        stri += str(dataset.models.parameters[p].value)  + '   ' +  str(dataset.models.parameters[p].error)  + '   '\n",
    "    print(stri)\n",
    "    if save:\n",
    "        with open(\"data/7a_P_draw_par.txt\", \"a\") as myfile:\n",
    "            myfile.write(stri + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "    fluxes = []\n",
    "    for e in ebins:\n",
    "        flux =  dataset.models[0].spectral_model(e)\n",
    "        fluxes.append(flux.value)\n",
    "\n",
    "    ff = str()\n",
    "    for f in fluxes:\n",
    "        ff += str(f) + \"  \"\n",
    "    #print(ff)\n",
    "    if save:\n",
    "        with open(\"data/7a_P_draw_flux.txt\", \"a\") as myfile:\n",
    "            myfile.write( ff + '\\n')\n",
    "\n",
    "\n",
    "    energy_bounds = (ebins[0], ebins[-1] ) * u.TeV\n",
    "\n",
    "    energy_min, energy_max = energy_bounds\n",
    "    energy = MapAxis.from_energy_bounds(\n",
    "        energy_min,\n",
    "        energy_max,\n",
    "        len(ebins),\n",
    "    )\n",
    "\n",
    "    fluxe2, _ = dataset.models[0].spectral_model._get_plot_flux(sed_type='dnde', energy=energy)\n",
    "    fluxe2 = scale_plot_flux(fluxe2, energy_power=2)\n",
    "    fluxe2 = fluxe2.quantity[:, 0, 0]\n",
    "    fluxe2 = np.array(fluxe2)   \n",
    "    ff = str()\n",
    "    for f in fluxe2:\n",
    "        ff += str(f) + \"  \"\n",
    "    if save:\n",
    "        with open(\"data/7a_P_draw_flux2e.txt\", \"a\") as myfile:\n",
    "            myfile.write( ff + '\\n')\n",
    "\n",
    "    energy_edges = dataset.geoms['geom'].axes[0].edges[::2]\n",
    "    if save_fluxpoints:\n",
    "        esti  = FluxPointsEstimator(energy_edges= energy_edges)\n",
    "        fluxpoints = esti.run([dataset])\n",
    "        fluxpoints.write(f'data/fluxpoints/6_fluxpoints_{shift_rnd[0]:.6}_{tilt_rnd[0]:.6}.fits')\n",
    "        Models([dataset.models[0]]).write(f'data/fluxpoints/6_model_{shift_rnd[0]:.6}_{tilt_rnd[0]:.6}.fits')\n",
    "        \n",
    "    if dataset_N:\n",
    "        dataset_N = sys_d_cor.create_dataset_N(e_reco_n = 10)\n",
    "        zero = 1e-24\n",
    "        dataset_N.models  = Models([dataset_N.models[0], dataset_N.background_model, IRFModels(eff_area_model = EffAreaIRFModel(),\n",
    "                                                                                              datasets_names=  dataset_N.name) ])\n",
    "        # addional parameter bias and resolution (ereco) but are frozen\n",
    "        penalising_invcovmatrix = np.zeros((2,2))\n",
    "        # 'bias', 'resolution', 'norm_nuisance',  'tilt_nuisance',\n",
    "        np.fill_diagonal(\n",
    "            penalising_invcovmatrix,\n",
    "            [ 1 / shift**2, 1 / tilt**2],\n",
    "        )\n",
    "        dataset_N.penalising_invcovmatrix = penalising_invcovmatrix\n",
    "        dataset_N.irf_model.eff_area_model.parameters['norm_nuisance'].frozen = False\n",
    "        dataset_N.irf_model.eff_area_model.parameters['tilt_nuisance'].frozen = False\n",
    "\n",
    "        fit_cor = Fit(store_trace=False)\n",
    "        result_cor = fit_cor.run([dataset_N])\n",
    "        \n",
    "        stri = \"\"\n",
    "        for p in ['amplitude', 'index', 'norm', 'tilt', 'norm_nuisance', 'tilt_nuisance']:\n",
    "            stri += str(dataset_N.models.parameters[p].value)  + '   ' +  str(dataset_N.models.parameters[p].error)  + '   '\n",
    "        print(stri)\n",
    "        if save:\n",
    "            with open(\"data/7a_N_P_draw_par.txt\", \"a\") as myfile:\n",
    "                myfile.write(stri + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "        fluxes = []\n",
    "        for e in ebins:\n",
    "            flux =  dataset_N.models[0].spectral_model(e)\n",
    "            fluxes.append(flux.value)\n",
    "\n",
    "        ff = str()\n",
    "        for f in fluxes:\n",
    "            ff += str(f) + \"  \"\n",
    "        #print(ff)\n",
    "        if save:\n",
    "            with open(\"data/7a_N_P_draw_flux.txt\", \"a\") as myfile:\n",
    "                myfile.write( ff + '\\n')\n",
    "\n",
    "\n",
    "        energy_bounds = (ebins[0], ebins[-1] ) * u.TeV\n",
    "\n",
    "        energy_min, energy_max = energy_bounds\n",
    "        energy = MapAxis.from_energy_bounds(\n",
    "            energy_min,\n",
    "            energy_max,\n",
    "            len(ebins),\n",
    "        )\n",
    "\n",
    "        fluxe2, _ = dataset_N.models[0].spectral_model._get_plot_flux(sed_type='dnde', energy=energy)\n",
    "        fluxe2 = scale_plot_flux(fluxe2, energy_power=2)\n",
    "        fluxe2 = fluxe2.quantity[:, 0, 0]\n",
    "        fluxe2 = np.array(fluxe2)   \n",
    "        ff = str()\n",
    "        for f in fluxe2:\n",
    "            ff += str(f) + \"  \"\n",
    "        if save:\n",
    "            with open(\"data/7a_N_P_draw_flux2e.txt\", \"a\") as myfile:\n",
    "                myfile.write( ff + '\\n')\n",
    "        \n",
    "        \n",
    "        if save_fluxpoints_N:\n",
    "           \n",
    "            esti  = FluxPointsEstimator(energy_edges= energy_edges)\n",
    "            fluxpoints_N = esti.run([dataset_N])\n",
    "            fluxpoints_N.write(f'data/fluxpoints/6_fluxpoints_N_{shift_rnd[0]:.6}_{tilt_rnd[0]:.6}.fits')\n",
    "            Models([dataset_N.models[0]]).write(f'data/fluxpoints/6_model_N_{shift_rnd[0]:.6}_{tilt_rnd[0]:.6}.fits')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

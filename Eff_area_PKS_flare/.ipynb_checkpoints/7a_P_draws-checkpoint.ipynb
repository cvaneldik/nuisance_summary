{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17be4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Runnning with gammapy-dev/IRF_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c102068e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'sys_dataset' from 'Dataset_Creation' (/home/katrin/Documents/nuisance_summary/Dataset_Creation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/katrin/Documents/nuisance_summary/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDataset_Creation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sys_dataset   \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mDataset_load\u001b[39;00m  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     37\u001b[0m pyximport\u001b[38;5;241m.\u001b[39minstall()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'sys_dataset' from 'Dataset_Creation' (/home/katrin/Documents/nuisance_summary/Dataset_Creation.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "def save():\n",
    "    with open(\"data/7aP_P_draw_info.txt\", \"a\") as myfile:\n",
    "        myfile.write(str(float(bias_rnd[0])) + '    '+ str(float(res_rnd[0])) + '    ' +  str(float(dataset.stat_sum())) + '\\n')\n",
    "    with open(\"data/7aP_P_draw_par.txt\", \"a\") as myfile:\n",
    "        myfile.write(stri + '\\n')\n",
    "    with open(\"data/7aP_P_draw_flux.txt\", \"a\") as myfile:\n",
    "        myfile.write( ff + '\\n')\n",
    "    with open(\"data/7aP_P_draw_flux2e.txt\", \"a\") as myfile:\n",
    "        myfile.write( ff2 + '\\n')\n",
    "\n",
    "    with open(\"data/7aP_N_P_draw_par.txt\", \"a\") as myfile:\n",
    "        myfile.write(stri_N + '\\n')\n",
    "    with open(\"data/7aP_N_P_draw_flux.txt\", \"a\") as myfile:\n",
    "        myfile.write( ffN + '\\n')\n",
    "    with open(\"data/7aP_N_P_draw_flux2e.txt\", \"a\") as myfile:\n",
    "        myfile.write( ffN2 + '\\n')\n",
    "\n",
    "\n",
    "import gammapy \n",
    "import pyximport\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import sys\n",
    "from gammapy.modeling import Fit, Parameter, Parameters\n",
    "from gammapy.modeling.models import Models\n",
    "from gammapy.maps import MapAxis\n",
    "from gammapy.modeling.models.spectral import scale_plot_flux\n",
    "from gammapy.estimators import  FluxPointsEstimator\n",
    "from gammapy.modeling.models import IRFModels, EffAreaIRFModel, ERecoIRFModel\n",
    "    \n",
    "sys.path.append('/home/katrin/Documents/nuisance_summary/')\n",
    "sys.path.append('../../../') \n",
    "from Dataset_Creation import sys_dataset   # noqa: E402\n",
    "import Dataset_load  # noqa: E402\n",
    "\n",
    "\n",
    "pyximport.install()\n",
    "\n",
    "print(f'loaded gammapy version: {gammapy.__version__} ' )\n",
    "print('Supposed to be 1.0 (21-12-2022)' )\n",
    "\n",
    "\n",
    "\n",
    "scaled_amplitude = Parameter(\"amplitude\", value=1e-11)\n",
    "lambda_ = Parameter(\"lambda_\", value=1/60)\n",
    "\n",
    "dataset_asimov = Dataset_load.create_asimov(\n",
    "    model=\"ecpl\", source=\"PKSflare\", parameters=Parameters([scaled_amplitude, lambda_])\n",
    ")\n",
    "\n",
    "mask = dataset_asimov.mask.data.sum(axis=2).sum(axis=1)>0\n",
    "\n",
    "ebins = dataset_asimov.counts.geom.axes[0].center[mask]\n",
    "print(len(ebins))\n",
    "\n",
    "\n",
    "shift = 0.\n",
    "tilt = 0.\n",
    "resolution = 0.\n",
    "bias = 0.1\n",
    "\n",
    "N = 10\n",
    "\n",
    "save_flux = True\n",
    "save_fluxpoints = 1\n",
    "save_fluxpoints_N = 0\n",
    "dataset_N = True\n",
    "\n",
    "\n",
    "for n in range(N):\n",
    "    print()\n",
    "    print('====' * 30)\n",
    "    print(n)\n",
    "    print('====' * 30)\n",
    "    res_rnd = [0.] \n",
    "    #res_rnd = np.random.normal(0, resolution, 1)\n",
    "    bias_rnd = np.random.normal(0, bias, 1)\n",
    "    \n",
    "    print(f\"res {res_rnd}, bias {bias_rnd}\")\n",
    "    sys_d_cor = sys_dataset(dataset_asimov= dataset_asimov,\n",
    "                    shift = 0, \n",
    "                    tilt = 0,\n",
    "                    resolution = res_rnd[0],\n",
    "                    bias = bias_rnd,\n",
    "                    rnd = True)\n",
    "    dataset = sys_d_cor.create_dataset()\n",
    "    \n",
    "    fit_cor = Fit(store_trace=False)\n",
    "    result_cor = fit_cor.run([dataset])\n",
    "\n",
    "\n",
    "    stri = \"\"\n",
    "    for p in ['amplitude', 'index', 'lambda_', 'norm', 'tilt']:\n",
    "        stri += str(dataset.models.parameters[p].value)  + '   ' +  str(dataset.models.parameters[p].error)  + '   '\n",
    "    print(stri)\n",
    "\n",
    "\n",
    "    fluxes = []\n",
    "    for e in ebins:\n",
    "        flux =  dataset.models[0].spectral_model(e)\n",
    "        fluxes.append(flux.value)\n",
    "\n",
    "    ff = str()\n",
    "    for f in fluxes:\n",
    "        ff += str(f) + \"  \"\n",
    "    #print(ff)\n",
    "\n",
    "    energy_bounds = (ebins[0], ebins[-1] ) * u.TeV\n",
    "\n",
    "    energy_min, energy_max = energy_bounds\n",
    "    energy = MapAxis.from_energy_bounds(\n",
    "        energy_min,\n",
    "        energy_max,\n",
    "        len(ebins),\n",
    "    )\n",
    "\n",
    "    fluxe2, _ = dataset.models[0].spectral_model._get_plot_flux(sed_type='dnde', energy=energy)\n",
    "    fluxe2 = scale_plot_flux(fluxe2, energy_power=2)\n",
    "    fluxe2 = fluxe2.quantity[:, 0, 0]\n",
    "    fluxe2 = np.array(fluxe2)   \n",
    "    ff2 = str()\n",
    "    for f in fluxe2:\n",
    "        ff2 += str(f) + \"  \"\n",
    "\n",
    "    energy_edges = dataset.geoms['geom'].axes[0].edges[::2]\n",
    "       \n",
    "        \n",
    "    dataset_N = sys_d_cor.create_dataset_N(e_reco_n = 10, counts = dataset.counts)\n",
    "    zero = 1e-24\n",
    "    dataset_N.models  = Models([dataset_N.models[0], dataset_N.background_model, IRFModels(eff_area_model = None,\n",
    "                                                                                           e_reco_model = ERecoIRFModel(),\n",
    "                                                                                          datasets_names=  dataset_N.name) ])\n",
    "    # addional parameter bias and resolution (ereco) but are frozen\n",
    "    penalising_invcovmatrix = np.zeros((2,2))\n",
    "    # 'bias', 'resolution', 'norm_nuisance',  'tilt_nuisance',\n",
    "    np.fill_diagonal(\n",
    "        penalising_invcovmatrix,\n",
    "        [ 1 / bias**2, 1 / zero**2],\n",
    "    )\n",
    "    dataset_N.penalising_invcovmatrix = penalising_invcovmatrix\n",
    "    dataset_N.irf_model.e_reco_model.parameters['bias'].frozen = False\n",
    "    dataset_N.irf_model.e_reco_model.parameters['resolution'].frozen = True\n",
    "\n",
    "    fit_cor = Fit(store_trace=False)\n",
    "    result_cor = fit_cor.run([dataset_N])\n",
    "\n",
    "    stri_N = \"\"\n",
    "    for p in ['amplitude', 'index', 'lambda_', 'norm', 'tilt', 'bias', 'resolution']:\n",
    "        stri_N += str(dataset_N.models.parameters[p].value)  + '   ' +  str(dataset_N.models.parameters[p].error)  + '   '\n",
    "    print(stri_N)\n",
    "\n",
    "\n",
    "    fluxes = []\n",
    "    for e in ebins:\n",
    "        flux =  dataset_N.models[0].spectral_model(e)\n",
    "        fluxes.append(flux.value)\n",
    "\n",
    "    ffN = str()\n",
    "    for f in fluxes:\n",
    "        ffN += str(f) + \"  \"\n",
    "\n",
    "    energy_bounds = (ebins[0], ebins[-1] ) * u.TeV\n",
    "\n",
    "    energy_min, energy_max = energy_bounds\n",
    "    energy = MapAxis.from_energy_bounds(\n",
    "        energy_min,\n",
    "        energy_max,\n",
    "        len(ebins),\n",
    "    )\n",
    "\n",
    "    fluxe2, _ = dataset_N.models[0].spectral_model._get_plot_flux(sed_type='dnde', energy=energy)\n",
    "    fluxe2 = scale_plot_flux(fluxe2, energy_power=2)\n",
    "    fluxe2 = fluxe2.quantity[:, 0, 0]\n",
    "    fluxe2 = np.array(fluxe2)   \n",
    "    ffN2 = str()\n",
    "    for f in fluxe2:\n",
    "        ffN2 += str(f) + \"  \"\n",
    "\n",
    "\n",
    "    if save_fluxpoints:\n",
    "\n",
    "        esti  = FluxPointsEstimator(energy_edges= energy_edges)\n",
    "        fluxpoints = esti.run([dataset])\n",
    "        esti  = FluxPointsEstimator(energy_edges= energy_edges)\n",
    "        fluxpoints_N = esti.run([dataset_N])\n",
    "        fluxpoints_N.write(f'data/fluxpoints/6P_fluxpoints_N_{bias_rnd[0]:.6}_{res_rnd[0]:.6}.fits')\n",
    "        Models([dataset_N.models[0]]).write(f'data/fluxpoints/6P_model_N_{bias_rnd[0]:.6}_{res_rnd[0]:.6}.yaml')\n",
    "        fluxpoints.write(f'data/fluxpoints/6P_fluxpoints_{bias_rnd[0]:.6}_{res_rnd[0]:.6}.fits')\n",
    "        Models([dataset.models[0]]).write(f'data/fluxpoints/6P_model_{bias_rnd[0]:.6}_{res_rnd[0]:.6}.yaml')\n",
    "\n",
    "    save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99404502-0567-4455-b933-4cd72ee9c69a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9b498-a86b-4ae1-af1f-8a21cdb1701c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset:\n",
      "/home/wecapstor1/caph/mppi045h/nuisance_summary/PKS_flare/HESS_public/dataset-simulated-2.154434690031884-hr.fits.gz\n",
      "\n",
      "========================================================================================================================\n",
      "0\n",
      "========================================================================================================================\n",
      "shift [0.], tilt [0.],  bias [-0.02855541], res [0.]\n",
      "random seed\n",
      "shift 1.0\n",
      "fit w/o nui ended:\n",
      "OptimizeResult\n",
      "\n",
      "\tbackend    : minuit\n",
      "\tmethod     : migrad\n",
      "\tsuccess    : True\n",
      "\tmessage    : Optimization terminated successfully.\n",
      "\tnfev       : 219\n",
      "\ttotal stat : 89417.08\n",
      "\n",
      "CovarianceResult\n",
      "\n",
      "\tbackend    : minuit\n",
      "\tmethod     : hesse\n",
      "\tsuccess    : True\n",
      "\tmessage    : Hesse terminated successfully.\n",
      "\n",
      "DatasetModels\n",
      "\n",
      "Component 0: SkyModel\n",
      "\n",
      "  Name                      : Crablog\n",
      "  Datasets names            : None\n",
      "  Spectral model type       : ExpCutoffPowerLawSpectralModel\n",
      "  Spatial  model type       : PointSpatialModel\n",
      "  Temporal model type       : \n",
      "  Parameters:\n",
      "    index                      :      2.355  +/-    0.09             \n",
      "    amplitude                  :   4.16e-11  +/- 2.9e-12 1 / (cm2 s TeV)\n",
      "    reference  (frozen)        :      1.000      TeV         \n",
      "    lambda_                    :      0.113  +/-    0.04 1 / TeV     \n",
      "    alpha      (frozen)        :      1.000                  \n",
      "    lon_0                      :    329.680  +/-    0.00 deg         \n",
      "    lat_0                      :    -30.220  +/-    0.00 deg         \n",
      "\n",
      "Component 1: FoVBackgroundModel\n",
      "\n",
      "  Name                      : dataset-bkg\n",
      "  Datasets names            : ['dataset']\n",
      "  Spectral model type       : PowerLawNormSpectralModel\n",
      "  Parameters:\n",
      "    norm                       :      1.002  +/-    0.01             \n",
      "    tilt                       :      0.006  +/-    0.01             \n",
      "    reference  (frozen)        :      1.000      TeV         \n",
      "\n",
      "\n",
      "4.156506364368248e-11   2.872270046197515e-12   2.354581068880149   0.08980777994557526   0.11336854614067643   0.04225814233189962   2.154434690031884  \n",
      "4.156506364368248e-11   2.872270046197515e-12   2.354581068880149   0.08980777994557526   0.11336854614067643   0.04225814233189962   2.154434690031884  1.0020326945306164   0.010744830159235118   0.006212585548442412   0.011602308340376758   2.154434690031884  \n"
     ]
    }
   ],
   "source": [
    "def save():\n",
    "    with open(f\"{path}/data/1_P_draw_info.txt\", \"a\") as myfile:\n",
    "        info = str(float(shift_rnd[0])) + '    '+ str(float(tilt_rnd[0])) + '    '\n",
    "        info += str(float(bias_rnd[0])) + '    '+ str(float(res_rnd[0])) + '    '\n",
    "        info +=  str(float(dataset.stat_sum())) + '\\n'\n",
    "        myfile.write(info)\n",
    "    with open(f\"{path}/data/1_P_draw_par.txt\", \"a\") as myfile:\n",
    "        myfile.write(stri + '\\n')\n",
    "    with open(f\"{path}/data/1_P_draw_flux.txt\", \"a\") as myfile:\n",
    "        myfile.write( ff + '\\n')\n",
    "    with open(f\"{path}/data/1_P_draw_flux2e.txt\", \"a\") as myfile:\n",
    "        myfile.write( ff2 + '\\n')\n",
    "\n",
    "    with open(f\"{path}/data/1_N_P_draw_par.txt\", \"a\") as myfile:\n",
    "        myfile.write(stri_N + '\\n')\n",
    "    with open(f\"{path}/data/1_N_P_draw_flux.txt\", \"a\") as myfile:\n",
    "        myfile.write( ffN + '\\n')\n",
    "    with open(f\"{path}/data/1_N_P_draw_flux2e.txt\", \"a\") as myfile:\n",
    "        myfile.write( ffN2 + '\\n')\n",
    "        \n",
    "def computing_contour(dataset, note):\n",
    "        \n",
    "    results = []\n",
    "    for parname1, parname2 in parameter_names :\n",
    "        numpoints = 5\n",
    "        print( parname1, parname2, numpoints)\n",
    "        result = fit_cor.stat_contour(dataset,\n",
    "                             dataset.models.parameters[parname1],\n",
    "                             dataset.models.parameters[parname2],\n",
    "                              numpoints=numpoints \n",
    "                                      \n",
    "                            )\n",
    "\n",
    "        contour_write = dict()\n",
    "        for k in result.keys():\n",
    "            print(k)\n",
    "            if k != \"success\":\n",
    "                contour_write[k] = result[k].tolist()\n",
    "        import yaml\n",
    "        with open(f\"{path}/data/contours/{note}_{parname1}_{parname2}.yml\", \"w\") as outfile:\n",
    "            yaml.dump(contour_write, outfile, default_flow_style=False)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "import gammapy \n",
    "import pyximport\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import sys\n",
    "from gammapy.modeling import Fit, Parameter, Parameters\n",
    "from gammapy.modeling.models import Models\n",
    "from gammapy.maps import MapAxis\n",
    "from gammapy.modeling.models.spectral import scale_plot_flux\n",
    "from gammapy.estimators import  FluxPointsEstimator\n",
    "from gammapy.modeling.models import IRFModels, EffAreaIRFModel, ERecoIRFModel\n",
    "    \n",
    "sys.path.append('/home/katrin/Documents/nuisance_summary/')\n",
    "sys.path.append('../')\n",
    "import Dataset_load \n",
    "from  Dataset_Setup import Setup, GaussianCovariance_matrix\n",
    "\n",
    "\n",
    "c = Dataset_load.load_config()\n",
    "awo, aw, ewo, ew = c['_colors']  \n",
    "\n",
    "livetimes = c['livetimes']\n",
    "livetime = c['livetime']\n",
    "sys = c['sys']\n",
    "norm = c['norm'] \n",
    "tilt = c['tilt'] \n",
    "bias =  c['bias'] \n",
    "resolution = c['resolution'] \n",
    "path = f\"../{c['folder']}\"\n",
    "parameter_names = c['parameter_names']        \n",
    "\n",
    "#for live in livetimes[8:]:\n",
    "for live in [livetime]:\n",
    "\n",
    "    dataset_asimov = Dataset_load.create_asimov(\n",
    "        model=c['model'], source=c['source'], parameters=None,\n",
    "        livetime = f\"{live}-hr\"\n",
    "    )\n",
    "\n",
    "    mask = dataset_asimov.mask.data.sum(axis=2).sum(axis=1)>0\n",
    "    ebins = dataset_asimov.counts.geom.axes[0].center[mask]\n",
    "\n",
    "\n",
    "    N = 100\n",
    "    save_flux = True\n",
    "    save_fluxpoints = 0\n",
    "    save_fluxpoints_N = 0\n",
    "    dataset_N = True\n",
    "    contour = 0\n",
    "    zero_sys = 0\n",
    "\n",
    "\n",
    "    for n in range(N):\n",
    "        print()\n",
    "        print('====' * 30)\n",
    "        print(n)\n",
    "        print('====' * 30)\n",
    "        res_rnd = np.random.normal(0, resolution, 1)\n",
    "        bias_rnd =  np.random.normal(0, bias, 1)\n",
    "        shift_rnd = np.random.normal(0, norm, 1)\n",
    "        tilt_rnd = np.random.normal(0, tilt, 1)\n",
    "        rnd = \"False\"\n",
    "        \n",
    "        if zero_sys:\n",
    "            nn = 71#np.random.randint(0,100)\n",
    "            print(\"nn\", nn)\n",
    "            rnd = nn\n",
    "        else:\n",
    "            rnd = \"True\"\n",
    "        \n",
    "        if zero_sys:\n",
    "            shift_rnd, tilt_rnd = np.array([0.]), np.array([0.])\n",
    "            bias_rnd, res_rnd = np.array([0.]), np.array([0.])\n",
    "        \n",
    "        print(f\"shift {shift_rnd}, tilt {tilt_rnd},  bias {bias_rnd}, res {res_rnd}\")\n",
    "        setup = Setup(dataset_input=dataset_asimov, rnd = rnd)\n",
    "        setup.set_up_irf_sys(bias_rnd, res_rnd, shift_rnd, tilt_rnd)\n",
    "\n",
    "        dataset, dataset_N = setup.run()\n",
    "        # irf model\n",
    "        # happens in set_up_irf_sys\n",
    "        # setup.set_irf_model(dataset_N)\n",
    "        if  \"Eff_area\" in sys:\n",
    "            dataset_N.models.parameters['resolution'].frozen = True\n",
    "            dataset_N.models.parameters['bias'].frozen = True\n",
    "            dataset_N.irf_model.parameters['tilt'].frozen = False\n",
    "            dataset_N.irf_model.parameters['norm'].frozen = False\n",
    "            dataset_N.e_reco_n = 10\n",
    "            setup.set_irf_prior(dataset_N, bias, resolution, norm, tilt)\n",
    "            print(dataset_N.irf_model)\n",
    "            \n",
    "        if sys == \"E_reco\":\n",
    "            dataset_N.models.parameters['resolution'].frozen = True\n",
    "            dataset_N.models.parameters['bias'].frozen = False\n",
    "            dataset_N.irf_model.parameters['tilt'].frozen = True\n",
    "            dataset_N.irf_model.parameters['norm'].frozen = True\n",
    "            dataset_N.e_reco_n = 1000\n",
    "            setup.set_irf_prior(dataset_N, bias, resolution, norm, tilt)\n",
    "        \n",
    "        if  \"Combined\"  in sys:\n",
    "            dataset_N.models.parameters['resolution'].frozen = True\n",
    "            dataset_N.models.parameters['bias'].frozen = False\n",
    "            dataset_N.irf_model.parameters['tilt'].frozen = False\n",
    "            dataset_N.irf_model.parameters['norm'].frozen = False\n",
    "            setup.set_irf_prior(dataset_N, bias, resolution, norm, tilt)\n",
    "            \n",
    "        if sys == \"BKG\":\n",
    "            magnitude = c['magnitude']\n",
    "            corrlength = c['corrlength']\n",
    "            # piece wise model\n",
    "            # remove old bkg model\n",
    "            setup.set_up_bkg_sys_V( breake = 10,\n",
    "                                index1 = 2,\n",
    "                                index2 = 1.5, \n",
    "                                magnitude = magnitude )\n",
    "\n",
    "            dataset_asimov, dataset_asimov_N = setup.run()\n",
    "\n",
    "            setup.unset_model(dataset_asimov_N, FoVBackgroundModel)\n",
    "            setup.set_piecewise_bkg_model(dataset_asimov_N)\n",
    "            # energy of the following parameters smaller than ethrshold\n",
    "            dataset_asimov_N.background_model.parameters['norm0'].frozen = True\n",
    "            dataset_asimov_N.background_model.parameters['norm1'].frozen = True\n",
    "            dataset_asimov_N.background_model.parameters['norm2'].frozen = True\n",
    "            dataset_asimov_N.background_model.parameters['norm3'].frozen = True\n",
    "            setup.set_bkg_prior(dataset_asimov_N, magnitude, corrlength)\n",
    "            frozen_pos = 1\n",
    "            if frozen_pos:\n",
    "                dataset_asimov.models.parameters['lon_0'].frozen = True\n",
    "                dataset_asimov.models.parameters['lat_0'].frozen = True\n",
    "                dataset_asimov_N.models.parameters['lon_0'].frozen = True\n",
    "                dataset_asimov_N.models.parameters['lat_0'].frozen = True\n",
    "        \n",
    "        fit_cor = Fit(store_trace=False)\n",
    "        dataset.plot_residuals()\n",
    "        result_cor = fit_cor.run([dataset])\n",
    "        print(\"fit w/o nui ended:\")\n",
    "        print(result_cor)\n",
    "        print(dataset.models)\n",
    "\n",
    "        stri = \"\"\n",
    "        parameters =  ['amplitude', 'index', 'lambda_',]# 'norm', 'tilt']\n",
    "        if \"crab_break\" in c['model']:\n",
    "            parameters =  ['amplitude', 'index1', 'index2', 'ebreak', 'beta',]# 'norm', 'tilt']\n",
    "        if \"crab_log\" in c['model']:\n",
    "            parameters =  ['amplitude', 'alpha', 'beta',]# 'norm', 'tilt']\n",
    "            \n",
    "        for p in parameters:\n",
    "            stri += str(dataset.models.parameters[p].value)  + '   ' +  str(dataset.models.parameters[p].error)  + '   '\n",
    "        stri += str(live) + \"  \"\n",
    "        print(stri)\n",
    "\n",
    "        for p in ['norm', 'tilt']:\n",
    "            stri += str(dataset.background_model.parameters[p].value)  + '   ' +  str(dataset.background_model.parameters[p].error)  + '   '\n",
    "        stri += str(live) + \"  \"\n",
    "        print(stri)\n",
    "     \n",
    "        energy_edges = dataset.geoms['geom'].axes[0].edges#[::2]\n",
    "        energy_bounds = (energy_edges[0], energy_edges[-1] ) #* u.TeV\n",
    "\n",
    "        energy_min, energy_max = energy_bounds\n",
    "        energy = MapAxis.from_energy_bounds(\n",
    "            energy_min,\n",
    "            energy_max,\n",
    "            len(energy_edges),\n",
    "            node_type='center'\n",
    "        )\n",
    "        fluxe2, _ = dataset.models[0].spectral_model._get_plot_flux(sed_type='dnde', energy=energy)\n",
    "        fluxe2 = scale_plot_flux(fluxe2, energy_power=2)\n",
    "        fluxe2 = fluxe2.quantity[:, 0, 0]\n",
    "        fluxe2 = np.array(fluxe2)   \n",
    "        ff2 = str()\n",
    "        for f in fluxe2:\n",
    "            ff2 += str(f) + \"  \"\n",
    "\n",
    "        fluxes = []\n",
    "        for e in energy.center:\n",
    "            flux =  dataset.models[0].spectral_model(e)\n",
    "            fluxes.append(flux.value)\n",
    "\n",
    "        ff = str()\n",
    "        for f in fluxes:\n",
    "            ff += str(f) + \"  \"\n",
    "        #print(ff)\n",
    "        fit_cor = Fit(store_trace=False)\n",
    "        result_cor = fit_cor.run([dataset_N])\n",
    "        print()\n",
    "        print(\"fit with nui ended:\")\n",
    "        print(result_cor)\n",
    "        print(dataset_N.models)\n",
    "\n",
    "\n",
    "        stri_N = \"\"\n",
    "        for p in parameters:\n",
    "            stri_N += str(dataset_N.models.parameters[p].value)  + '   ' +  str(dataset_N.models.parameters[p].error)  + '   '\n",
    "        for p in ['norm', 'tilt']:\n",
    "            stri_N += str(dataset_N.background_model.parameters[p].value)  + '   ' +  str(dataset_N.background_model.parameters[p].error)  + '   '\n",
    "        parameters_  =  ['norm', 'tilt', 'bias', 'resolution']\n",
    "        for p in parameters_:\n",
    "            stri_N += str(dataset_N.irf_model.parameters[p].value)  + '   ' +  str(dataset_N.irf_model.parameters[p].error)  + '   '\n",
    "        \n",
    "        stri_N += str(live) + \"  \"\n",
    "        print(stri_N)\n",
    "\n",
    "        fluxes = []\n",
    "        for e in energy.center:\n",
    "            flux =  dataset_N.models[0].spectral_model(e)\n",
    "            fluxes.append(flux.value)\n",
    "\n",
    "        ffN = str()\n",
    "        for f in fluxes:\n",
    "            ffN += str(f) + \"  \"\n",
    "\n",
    " \n",
    "        fluxe2, _ = dataset_N.models[0].spectral_model._get_plot_flux(sed_type='dnde', energy=energy)\n",
    "        fluxe2 = scale_plot_flux(fluxe2, energy_power=2)\n",
    "        fluxe2 = fluxe2.quantity[:, 0, 0]\n",
    "        fluxe2 = np.array(fluxe2)   \n",
    "        ffN2 = str()\n",
    "        for f in fluxe2:\n",
    "            ffN2 += str(f) + \"  \"\n",
    "\n",
    "        rnds = f\"{shift_rnd[0]:.6}_{tilt_rnd[0]:.6}_{bias_rnd[0]:.6}_{res_rnd[0]:.6}\"\n",
    "        if save_fluxpoints:\n",
    "            print(\"computing Fluxpoints\")\n",
    "            dataset.models.parameters['amplitude'].scan_n_sigma  = 5\n",
    "            dataset_N.models.parameters['amplitude'].scan_n_sigma  = 5\n",
    "\n",
    "            esti  = FluxPointsEstimator(energy_edges= energy_edges[::2][:-1], \n",
    "                                        selection_optional =  [ \"ul\"],\n",
    "                                        norm_min=0.2,\n",
    "                                    norm_max=200,\n",
    "                                    norm_n_values=15,\n",
    "                                       )\n",
    "            fluxpoints = esti.run([dataset])\n",
    "            import matplotlib.pyplot as plt\n",
    "            fig = plt.figure()\n",
    "            ax = fluxpoints.plot()\n",
    "            \n",
    "            # freeze all but IRF for fp and reopt = True\n",
    "            dataset_N.models[0].parameters.freeze_all()\n",
    "            dataset_N.models[0].parameters['amplitude'].frozen = False\n",
    "            dataset_N.background_model.parameters.freeze_all()\n",
    "            esti_  = FluxPointsEstimator(energy_edges= energy_edges[::2][:-1], selection_optional =[ \"ul\"],# \"errn-errp\", \"all\",\n",
    "                                        norm_min=0.2,\n",
    "                                    norm_max=200,\n",
    "                                    norm_n_values=15,\n",
    "                                       reoptimize=True)\n",
    "            fluxpoints_N = esti_.run([dataset_N])\n",
    "            fluxpoints_N.plot(ax = ax)\n",
    "            ax.legend(title = f\"live: {live:.3} hr\\n norm:{shift_rnd[0]:.3}\\n tilt:{tilt_rnd[0]:.3}\\n bias:{bias_rnd[0]:.3}\")\n",
    "            fig.savefig(f\"{path}/data/fluxpoints/plots/{live}_{rnds}_{nn}.png\")\n",
    "            \n",
    "            fluxpoints_N.write(f'{path}/data/fluxpoints/1P_fluxpoints_N_{live}_{rnds}_{nn}.fits',\n",
    "                              overwrite = True)\n",
    "            dataset_N.models.write(f'{path}/data/fluxpoints/1P_model_N_{live}_{rnds}_{nn}.yaml',\n",
    "                                  overwrite = True)\n",
    "            fluxpoints.write(f'{path}/data/fluxpoints/1P_fluxpoints_{live}_{rnds}_{nn}.fits',\n",
    "                            overwrite = True)\n",
    "            dataset.models.write(f'{path}/data/fluxpoints/1P_model_{live}_{rnds}_{nn}.yaml',\n",
    "                                overwrite = True)\n",
    "            with open(f\"{path}/data/fluxpoints/1P_draw_fluxpoints.txt\", \"a\") as myfile:\n",
    "                myfile.write(str(nn) + '\\n')\n",
    "        if contour:\n",
    "            computing_contour(dataset, rnds)\n",
    "            print(\"N\")\n",
    "            computing_contour(dataset_N, \"N\"+rnds)\n",
    "            with open(f\"{path}/data/contours/1_P_draw_info.txt\", \"a\") as myfile:\n",
    "                info = str(float(shift_rnd[0])) + '    '+ str(float(tilt_rnd[0])) + '    '\n",
    "                info += str(float(bias_rnd[0])) + '    '+ str(float(res_rnd[0])) + '    '\n",
    "                info +=  str(float(dataset.stat_sum())) + '\\n'\n",
    "                myfile.write(info)\n",
    "            with open(f\"{path}/data/contours/1_P_draw_par.txt\", \"a\") as myfile:\n",
    "                myfile.write(stri + '\\n')\n",
    "\n",
    "            with open(f\"{path}/data/contours/1_N_P_draw_par.txt\", \"a\") as myfile:\n",
    "                myfile.write(stri_N + '\\n')\n",
    "\n",
    "        if zero_sys == False and contour ==False: # else only the fluxpoints and models are saved but not the info\n",
    "            save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c434e-99ab-426d-adb9-afd9d02ed331",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f9836-a67f-4b04-94ba-a5cfabdb8d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot_residuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124952b9-54a3-4685-b571-6687b6199a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_N.plot_residuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e504e-c3d4-440a-8ef1-e5c2b8a056d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fluxpoints_N.plot(energy_power = 2, capsize = 4, color = 'tab:blue')\n",
    "fluxpoints.plot(ax = ax, energy_power = 2,  capsize = 4, color = 'tab:orange')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3043f-74d8-44f6-b7a2-1b266136209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxpoints_N.sqrt_ts.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93adaa9d-7b6d-450b-84ba-cc19426121b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37691fe8-d648-454c-8e76-03b91e6940ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fluxpoints.plot(energy_power = 2, capsize = 4, color = 'tab:blue')\n",
    "fluxpoints_N.plot(ax = ax, energy_power = 2,  capsize = 4, color = 'tab:orange')\n",
    "dataset_N.models[0].spectral_model.plot(energy_power = 2, color = 'tab:orange')\n",
    "dataset.models[0].spectral_model.plot(energy_power = 2, color = 'tab:blue')\n",
    "dataset.models[0].spectral_model.plot_error(energy_power = 2, ax = ax, facecolor = 'tab:blue')\n",
    "dataset_N.models[0].spectral_model.plot_error(energy_power = 2, ax = ax, facecolor = 'tab:orange')\n",
    "\n",
    "ax.legend(title = f\"live: {live:.3} hr\\n norm:{shift_rnd[0]:.3}\\n tilt:{tilt_rnd[0]:.3}\\n bias:{bias_rnd[0]:.3}\")\n",
    "#ax.set_ylim(5e-13, 0.8e-10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93262a88-e7be-4b5c-9991-215d5f2a9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffc250-efbd-4b72-b098-c4c14184aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8c558-cae5-49a5-99b2-bd2d8fe0cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_N.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107d785-cf91-4f21-9d0f-efc51f7157a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

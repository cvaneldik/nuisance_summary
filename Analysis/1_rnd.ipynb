{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8407755b-77a1-4ad5-bd7f-9f81e956e0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset:\n",
      "/home/wecapstor1/caph/mppi045h/nuisance_summary/PKS_flare/HESS_public/dataset-simulated-2.154434690031884-hr.fits.gz\n",
      "\n",
      "========================================================================================================================\n",
      "0\n",
      "========================================================================================================================\n",
      "shift [0.12614003], tilt [-0.00654031]  bias [0.], res [0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def save():\n",
    "    with open(f\"{path}/data/1_P_draw_info.txt\", \"a\") as myfile:\n",
    "        info = str(float(shift_rnd[0])) + '    '+ str(float(tilt_rnd[0])) + '    '\n",
    "        info += str(float(bias_rnd[0])) + '    '+ str(float(res_rnd[0])) + '    '\n",
    "        info +=  str(float(dataset.stat_sum())) + '\\n'\n",
    "        myfile.write(info)\n",
    "    with open(f\"{path}/data/1_P_draw_par.txt\", \"a\") as myfile:\n",
    "        myfile.write(stri + '\\n')\n",
    "    with open(f\"{path}/data/1_P_draw_flux.txt\", \"a\") as myfile:\n",
    "        myfile.write( ff + '\\n')\n",
    "    with open(f\"{path}/data/1_P_draw_flux2e.txt\", \"a\") as myfile:\n",
    "        myfile.write( ff2 + '\\n')\n",
    "\n",
    "    with open(f\"{path}/data/1_N_P_draw_par.txt\", \"a\") as myfile:\n",
    "        myfile.write(stri_N + '\\n')\n",
    "    with open(f\"{path}/data/1_N_P_draw_flux.txt\", \"a\") as myfile:\n",
    "        myfile.write( ffN + '\\n')\n",
    "    with open(f\"{path}/data/1_N_P_draw_flux2e.txt\", \"a\") as myfile:\n",
    "        myfile.write( ffN2 + '\\n')\n",
    "\n",
    "\n",
    "import gammapy \n",
    "import pyximport\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import sys\n",
    "from gammapy.modeling import Fit, Parameter, Parameters\n",
    "from gammapy.modeling.models import Models\n",
    "from gammapy.maps import MapAxis\n",
    "from gammapy.modeling.models.spectral import scale_plot_flux\n",
    "from gammapy.estimators import  FluxPointsEstimator\n",
    "from gammapy.modeling.models import IRFModels, EffAreaIRFModel, ERecoIRFModel\n",
    "    \n",
    "sys.path.append('/home/katrin/Documents/nuisance_summary/')\n",
    "sys.path.append('../')\n",
    "import Dataset_load \n",
    "from  Dataset_Setup import Setup, GaussianCovariance_matrix\n",
    "\n",
    "\n",
    "c = Dataset_load.load_config()\n",
    "awo, aw, ewo, ew = c['_colors']  \n",
    "\n",
    "livetimes = c['livetimes']\n",
    "livetime = c['livetime']\n",
    "sys = c['sys']\n",
    "norm = 0.5 #c['norm'] \n",
    "tilt = c['tilt'] \n",
    "bias = c['bias'] \n",
    "resolution = c['resolution'] \n",
    "path = f\"../{c['folder']}\"\n",
    "\n",
    "#for live in livetimes:\n",
    "for live in [livetime]:\n",
    "\n",
    "    dataset_asimov = Dataset_load.create_asimov(\n",
    "        model=c['model'], source=c['source'], parameters=None,\n",
    "        livetime = f\"{live}-hr\"\n",
    "    )\n",
    "\n",
    "    mask = dataset_asimov.mask.data.sum(axis=2).sum(axis=1)>0\n",
    "    ebins = dataset_asimov.counts.geom.axes[0].center[mask]\n",
    "\n",
    "\n",
    "    N = 1\n",
    "    save_flux = True\n",
    "    save_fluxpoints = 1\n",
    "    save_fluxpoints_N = 1\n",
    "    dataset_N = True\n",
    "\n",
    "\n",
    "    for n in range(N):\n",
    "        print()\n",
    "        print('====' * 30)\n",
    "        print(n)\n",
    "        print('====' * 30)\n",
    "        res_rnd = np.random.normal(0, resolution, 1)\n",
    "        bias_rnd =  np.random.normal(0, bias, 1)\n",
    "        shift_rnd = np.random.normal(0, norm, 1)\n",
    "        tilt_rnd = np.random.normal(0, tilt, 1)\n",
    "\n",
    "        print(f\"shift {shift_rnd}, tilt {tilt_rnd}  bias {bias_rnd}, res {res_rnd}\")\n",
    "        setup = Setup(dataset_input=dataset_asimov, rnd = True)\n",
    "        #setup.set_up_irf_sys(bias, resolution, norm, tilt)\n",
    "        dataset, dataset_N = setup.run()\n",
    "        # irf model\n",
    "        setup.set_irf_model(dataset_N)\n",
    "        if sys == \"Eff_area\":\n",
    "            dataset_N.models.parameters['resolution'].frozen = True\n",
    "            dataset_N.models.parameters['bias'].frozen = True\n",
    "            dataset_N.irf_model.parameters['tilt'].frozen = False\n",
    "            dataset_N.irf_model.parameters['norm'].frozen = False\n",
    "        setup.set_irf_prior(dataset_N, bias, resolution, norm, tilt)\n",
    "        fit_cor = Fit(store_trace=False)\n",
    "        result_cor = fit_cor.run([dataset])\n",
    "\n",
    "\n",
    "        stri = \"\"\n",
    "        parameters =  ['amplitude', 'index', 'lambda_', 'norm', 'tilt']\n",
    "        if c['model'] == \"crab_break\":\n",
    "            parameters =  ['amplitude', 'index1', 'index2', 'ebreak', 'beta', 'norm', 'tilt']\n",
    "            \n",
    "        for p in parameters:\n",
    "            stri += str(dataset.models.parameters[p].value)  + '   ' +  str(dataset.models.parameters[p].error)  + '   '\n",
    "        stri += str(live) + \"  \"\n",
    "        print(stri)\n",
    "\n",
    "\n",
    "        fluxes = []\n",
    "        for e in ebins:\n",
    "            flux =  dataset.models[0].spectral_model(e)\n",
    "            fluxes.append(flux.value)\n",
    "\n",
    "        ff = str()\n",
    "        for f in fluxes:\n",
    "            ff += str(f) + \"  \"\n",
    "        #print(ff)\n",
    "\n",
    "        energy_bounds = (ebins[0], ebins[-1] ) * u.TeV\n",
    "\n",
    "        energy_min, energy_max = energy_bounds\n",
    "        energy = MapAxis.from_energy_bounds(\n",
    "            energy_min,\n",
    "            energy_max,\n",
    "            len(ebins),\n",
    "        )\n",
    "\n",
    "        fluxe2, _ = dataset.models[0].spectral_model._get_plot_flux(sed_type='dnde', energy=energy)\n",
    "        fluxe2 = scale_plot_flux(fluxe2, energy_power=2)\n",
    "        fluxe2 = fluxe2.quantity[:, 0, 0]\n",
    "        fluxe2 = np.array(fluxe2)   \n",
    "        ff2 = str()\n",
    "        for f in fluxe2:\n",
    "            ff2 += str(f) + \"  \"\n",
    "\n",
    "        energy_edges = dataset.geoms['geom'].axes[0].edges[::2]\n",
    "\n",
    "        fit_cor = Fit(store_trace=False)\n",
    "        result_cor = fit_cor.run([dataset_N])\n",
    "\n",
    "        stri_N = \"\"\n",
    "        [parameters.append(p) for p in ['norm', 'tilt', 'bias', 'resolution']]\n",
    "        for p in parameters:\n",
    "            stri_N += str(dataset_N.models.parameters[p].value)  + '   ' +  str(dataset_N.models.parameters[p].error)  + '   '\n",
    "        stri_N += str(live) + \"  \"\n",
    "        print(stri_N)\n",
    "\n",
    "        fluxes = []\n",
    "        for e in ebins:\n",
    "            flux =  dataset_N.models[0].spectral_model(e)\n",
    "            fluxes.append(flux.value)\n",
    "\n",
    "        ffN = str()\n",
    "        for f in fluxes:\n",
    "            ffN += str(f) + \"  \"\n",
    "\n",
    "        energy_bounds = (ebins[0], ebins[-1] ) * u.TeV\n",
    "\n",
    "        energy_min, energy_max = energy_bounds\n",
    "        energy = MapAxis.from_energy_bounds(\n",
    "            energy_min,\n",
    "            energy_max,\n",
    "            len(ebins),\n",
    "        )\n",
    "\n",
    "        fluxe2, _ = dataset_N.models[0].spectral_model._get_plot_flux(sed_type='dnde', energy=energy)\n",
    "        fluxe2 = scale_plot_flux(fluxe2, energy_power=2)\n",
    "        fluxe2 = fluxe2.quantity[:, 0, 0]\n",
    "        fluxe2 = np.array(fluxe2)   \n",
    "        ffN2 = str()\n",
    "        for f in fluxe2:\n",
    "            ffN2 += str(f) + \"  \"\n",
    "\n",
    "        rnds = f\"{shift_rnd[0]:.6}_{tilt_rnd[0]:.6}_{bias_rnd[0]:.6}_{res_rnd[0]:.6}\"\n",
    "        if save_fluxpoints:\n",
    "            dataset.models.parameters['amplitude'].scan_n_sigma  = 5\n",
    "            dataset_N.models.parameters['amplitude'].scan_n_sigma  = 5\n",
    "            \n",
    "            esti  = FluxPointsEstimator(energy_edges= energy_edges, selection_optional = \"all\")\n",
    "            fluxpoints = esti.run([dataset])\n",
    "            esti  = FluxPointsEstimator(energy_edges= energy_edges, selection_optional = \"all\")\n",
    "            fluxpoints_N = esti.run([dataset_N])\n",
    "            fluxpoints_N.write(f'{path}/data/fluxpoints/1P_fluxpoints_N_{live}_{rnds}.fits')\n",
    "            dataset_N.models.write(f'{path}/data/fluxpoints/1P_model_N_{live}_{rnds}.yaml')\n",
    "            fluxpoints.write(f'{path}/data/fluxpoints/1P_fluxpoints_{live}_{rnds}.fits')\n",
    "            dataset.models.write(f'{path}/data/fluxpoints/1P_model_{live}_{rnds}.yaml')\n",
    "\n",
    "        save()\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        ep = 2\n",
    "        ax = dataset.models[0].spectral_model.plot((0.1,100)*u.TeV, color = 'tab:blue',\n",
    "                                                  label = \"without nui\",\n",
    "                                                  energy_power = ep)\n",
    "\n",
    "\n",
    "        dataset_asimov.models[0].spectral_model.plot((0.1,100)*u.TeV,ax = ax, color = 'black',\n",
    "                                                    energy_power = ep)\n",
    "\n",
    "        dataset_N.models[0].spectral_model.plot((0.1,100)*u.TeV,ax = ax, color = 'tab:orange',\n",
    "                                               label = \"with nui\",\n",
    "                                               energy_power = ep)\n",
    "        dataset_N.models[0].spectral_model.plot_error((0.1,100)*u.TeV,ax = ax, facecolor = 'tab:orange',\n",
    "                                                     energy_power = ep)\n",
    "        dataset.models[0].spectral_model.plot_error((0.1,100)*u.TeV,ax = ax, facecolor = 'tab:blue',\n",
    "                                                   energy_power = ep)\n",
    "\n",
    "        fluxpoints_N.plot(ax =ax,energy_power = ep )\n",
    "        fluxpoints.plot(ax =ax, energy_power = ep)\n",
    "        ax.legend(title = f\"live: {live} hr norm:{shift_rnd[0]:.3} tilt:{tilt_rnd[0]:.3}\")\n",
    "        fig = plt.gcf()\n",
    "        fig.savefig(f\"{path}/data/plots/{live}_{rnds}.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fff8bb-e464-4d90-bd1f-d30018a49986",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_N\n",
    "\n",
    "datasets_sliced = dataset_N.slice_by_energy(\n",
    "            energy_min=1*u.TeV, energy_max=2*u.TeV)\n",
    "models = Models(dataset_N.models.copy())\n",
    "\n",
    "if dataset_N.irf_model is not None:\n",
    "    irf = IRFModels(eff_area_model=dataset_N.irf_model.eff_area_model.copy(),\n",
    "                    e_reco_model=dataset_N.irf_model.e_reco_model.copy(),\n",
    "                    datasets_names=datasets_sliced.name)\n",
    "    models.append(irf)\n",
    "    \n",
    "datasets_sliced.models = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083de7e6-ae4b-4346-8147-ebc3cbb6ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_sliced.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834e3ca-0a3f-4da3-a667-e44031a53c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasets_sliced.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2369b-b1d6-42cc-832a-b25ed5ccb7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxpoints.dnde_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda486c-1cd2-4f3e-bfdb-e047fcfc506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxpoints_N.dnde_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808802fc-1f2a-4743-9035-7c8e25fbcc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxpoints.dnde_err.data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f54802-abdd-4a01-a572-35cc28ae608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxpoints_N.dnde_err.data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c67c84-f6f8-47a5-aa0a-4ea2b0d425e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

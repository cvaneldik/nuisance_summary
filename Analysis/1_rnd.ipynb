{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8407755b-77a1-4ad5-bd7f-9f81e956e0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset:\n",
      "/home/wecapstor1/caph/mppi045h/nuisance_summary/PKS_flare/HESS_public/dataset-simulated-2.154434690031884-hr.fits.gz\n",
      "\n",
      "========================================================================================================================\n",
      "0\n",
      "========================================================================================================================\n",
      "shift [0.016572], tilt [0.00962207]  bias [0.], res [0.]\n",
      "3.6847120840462366e-11   1.7377226480813377e-12   2.619939505204093   0.05828630573254195   0.12816545311375294   0.053221237046314006   1.00564442791799   0.010766386322824582   0.014987743412770253   0.011654990730694191   2.154434690031884  \n",
      "3.85e-11   0.0   2.51   0.0   0.24   0.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0   0.0   0   2.154434690031884  \n",
      "amplitude alpha\n",
      "Crablog.spectral.amplitude\n",
      "Crablog.spectral.alpha\n",
      "success\n",
      "amplitude beta\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 218\u001b[0m\n\u001b[1;32m    216\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/fluxpoints/1P_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrnds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m contour:\n\u001b[0;32m--> 218\u001b[0m     \u001b[43mcomputing_contour\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     computing_contour(dataset_N, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mrnds)\n\u001b[1;32m    222\u001b[0m save()\n",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m, in \u001b[0;36mcomputing_contour\u001b[0;34m(dataset, note)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m parname1, parname2 \u001b[38;5;129;01min\u001b[39;00m parameter_names :\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m( parname1, parname2)\n\u001b[0;32m---> 26\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfit_cor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat_contour\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparname1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparname2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     contour_write \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/gammapy/gammapy/modeling/fit.py:526\u001b[0m, in \u001b[0;36mFit.stat_contour\u001b[0;34m(self, datasets, x, y, numpoints, sigma)\u001b[0m\n\u001b[1;32m    523\u001b[0m name_y \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mparameters_unique_names[i2]\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parameters\u001b[38;5;241m.\u001b[39mrestore_status():\n\u001b[0;32m--> 526\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcontour_iminuit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m x \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39mscale\n\u001b[1;32m    536\u001b[0m y \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m y\u001b[38;5;241m.\u001b[39mscale\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/gammapy/gammapy/modeling/iminuit.py:174\u001b[0m, in \u001b[0;36mcontour_iminuit\u001b[0;34m(parameters, function, x, y, numpoints, sigma, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m y \u001b[38;5;241m=\u001b[39m _make_parname(idx_y, par_y)\n\u001b[1;32m    173\u001b[0m cl \u001b[38;5;241m=\u001b[39m chi2(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcdf(sigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 174\u001b[0m contour \u001b[38;5;241m=\u001b[39m \u001b[43mminuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmncontour\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# TODO: add try and except to get the success\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: contour[:, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: contour[:, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    180\u001b[0m }\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/anaconda3/envs/gammapy-dev/lib/python3.8/site-packages/iminuit/minuit.py:1894\u001b[0m, in \u001b[0;36mMinuit.mncontour\u001b[0;34m(self, x, y, cl, size, interpolated)\u001b[0m\n\u001b[1;32m   1892\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fmin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1893\u001b[0m     mnc \u001b[38;5;241m=\u001b[39m MnContours(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fcn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fmin\u001b[38;5;241m.\u001b[39m_src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n\u001b[0;32m-> 1894\u001b[0m     ce \u001b[38;5;241m=\u001b[39m \u001b[43mmnc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   1896\u001b[0m pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ce)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;66;03m# add starting point at end to close the contour\u001b[39;00m\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/gammapy/gammapy/modeling/iminuit.py:25\u001b[0m, in \u001b[0;36mMinuitLikelihood.fcn\u001b[0;34m(self, *factors)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfcn\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mfactors):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mset_parameter_factors(factors)\n\u001b[0;32m---> 25\u001b[0m     total_stat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_trace:\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_trace_iteration(total_stat)\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/gammapy/gammapy/datasets/core.py:235\u001b[0m, in \u001b[0;36mDatasets.stat_sum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m prior_stat_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 235\u001b[0m     stat_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# remove prior_fit_statistic from individual dataset to avoid double counting\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mmodels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/gammapy/gammapy/datasets/map.py:1241\u001b[0m, in \u001b[0;36mMapDataset.stat_sum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstat_sum\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Total statistic function value given the current model parameters and priors set on the models.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1241\u001b[0m     counts, npred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounts\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnpred\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m   1242\u001b[0m     prior_stat_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/gammapy/gammapy/datasets/map.py:462\u001b[0m, in \u001b[0;36mMapDataset.npred\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m npred_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnpred_signal()\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackground:\n\u001b[0;32m--> 462\u001b[0m     npred_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnpred_background\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m npred_total\u001b[38;5;241m.\u001b[39mdata[npred_total\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m npred_total\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/gammapy/gammapy/datasets/map.py:569\u001b[0m, in \u001b[0;36mMapDataset.npred_background\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_background_cached \u001b[38;5;241m=\u001b[39m background \u001b[38;5;241m*\u001b[39m values\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_background_cached\u001b[38;5;241m.\u001b[39mquantity \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 569\u001b[0m                 \u001b[43mbackground\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantity\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\n\u001b[1;32m    570\u001b[0m             )\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_background_cached\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/anaconda3/envs/gammapy-dev/lib/python3.8/site-packages/astropy/units/quantity.py:1196\u001b[0m, in \u001b[0;36mQuantity.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnitsError:  \u001b[38;5;66;03m# let other try to deal with it\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m-> 1196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__mul__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/anaconda3/envs/gammapy-dev/lib/python3.8/site-packages/astropy/units/quantity.py:673\u001b[0m, in \u001b[0;36mQuantity.__array_ufunc__\u001b[0;34m(self, function, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m     arrays\u001b[38;5;241m.\u001b[39mappend(converter(input_) \u001b[38;5;28;01mif\u001b[39;00m converter \u001b[38;5;28;01melse\u001b[39;00m input_)\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# Call our superclass's __array_ufunc__\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__array_ufunc__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# If unit is None, a plain array is expected (e.g., comparisons), which\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# means we're done.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# We're also done if the result was None (for method 'at') or\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# NotImplemented, which can happen if other inputs/outputs override\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;66;03m# __array_ufunc__; hopefully, they can then deal with us.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def save():\n",
    "    with open(f\"{path}/data/1_P_draw_info.txt\", \"a\") as myfile:\n",
    "        info = str(float(shift_rnd[0])) + '    '+ str(float(tilt_rnd[0])) + '    '\n",
    "        info += str(float(bias_rnd[0])) + '    '+ str(float(res_rnd[0])) + '    '\n",
    "        info +=  str(float(dataset.stat_sum())) + '\\n'\n",
    "        myfile.write(info)\n",
    "    with open(f\"{path}/data/1_P_draw_par.txt\", \"a\") as myfile:\n",
    "        myfile.write(stri + '\\n')\n",
    "    with open(f\"{path}/data/1_P_draw_flux.txt\", \"a\") as myfile:\n",
    "        myfile.write( ff + '\\n')\n",
    "    with open(f\"{path}/data/1_P_draw_flux2e.txt\", \"a\") as myfile:\n",
    "        myfile.write( ff2 + '\\n')\n",
    "\n",
    "    with open(f\"{path}/data/1_N_P_draw_par.txt\", \"a\") as myfile:\n",
    "        myfile.write(stri_N + '\\n')\n",
    "    with open(f\"{path}/data/1_N_P_draw_flux.txt\", \"a\") as myfile:\n",
    "        myfile.write( ffN + '\\n')\n",
    "    with open(f\"{path}/data/1_N_P_draw_flux2e.txt\", \"a\") as myfile:\n",
    "        myfile.write( ffN2 + '\\n')\n",
    "        \n",
    "def computing_contour(dataset, note):\n",
    "        \n",
    "    results = []\n",
    "    for parname1, parname2 in parameter_names :\n",
    "        print( parname1, parname2)\n",
    "        result = fit_cor.stat_contour(dataset,\n",
    "                             dataset.models.parameters[parname1],\n",
    "                             dataset.models.parameters[parname2],\n",
    "                            )\n",
    "\n",
    "        contour_write = dict()\n",
    "        for k in result.keys():\n",
    "            print(k)\n",
    "            if k != \"success\":\n",
    "                contour_write[k] = result[k].tolist()\n",
    "        import yaml\n",
    "        with open(f\"{path}/data/contours/{note}_{parname1}_{parname2}.yml\", \"w\") as outfile:\n",
    "            yaml.dump(contour_write, outfile, default_flow_style=False)\n",
    "\n",
    "\n",
    "\n",
    "import gammapy \n",
    "import pyximport\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import sys\n",
    "from gammapy.modeling import Fit, Parameter, Parameters\n",
    "from gammapy.modeling.models import Models\n",
    "from gammapy.maps import MapAxis\n",
    "from gammapy.modeling.models.spectral import scale_plot_flux\n",
    "from gammapy.estimators import  FluxPointsEstimator\n",
    "from gammapy.modeling.models import IRFModels, EffAreaIRFModel, ERecoIRFModel\n",
    "    \n",
    "sys.path.append('/home/katrin/Documents/nuisance_summary/')\n",
    "sys.path.append('../')\n",
    "import Dataset_load \n",
    "from  Dataset_Setup import Setup, GaussianCovariance_matrix\n",
    "\n",
    "\n",
    "c = Dataset_load.load_config()\n",
    "awo, aw, ewo, ew = c['_colors']  \n",
    "\n",
    "livetimes = c['livetimes']\n",
    "livetime = c['livetime']\n",
    "sys = c['sys']\n",
    "norm = c['norm'] \n",
    "tilt = c['tilt'] \n",
    "bias = c['bias'] \n",
    "resolution = c['resolution'] \n",
    "path = f\"../{c['folder']}\"\n",
    "parameter_names = c['parameter_names']        \n",
    "\n",
    "#for live in livetimes:\n",
    "for live in [livetime]:\n",
    "\n",
    "    dataset_asimov = Dataset_load.create_asimov(\n",
    "        model=c['model'], source=c['source'], parameters=None,\n",
    "        livetime = f\"{live}-hr\"\n",
    "    )\n",
    "\n",
    "    mask = dataset_asimov.mask.data.sum(axis=2).sum(axis=1)>0\n",
    "    ebins = dataset_asimov.counts.geom.axes[0].center[mask]\n",
    "\n",
    "\n",
    "    N = 1\n",
    "    save_flux = True\n",
    "    save_fluxpoints = 0\n",
    "    save_fluxpoints_N = 0\n",
    "    dataset_N = True\n",
    "    contour = True\n",
    "\n",
    "\n",
    "    for n in range(N):\n",
    "        print()\n",
    "        print('====' * 30)\n",
    "        print(n)\n",
    "        print('====' * 30)\n",
    "        res_rnd = np.random.normal(0, resolution, 1)\n",
    "        bias_rnd =  np.random.normal(0, bias, 1)\n",
    "        shift_rnd = np.random.normal(0, norm, 1)\n",
    "        tilt_rnd = np.random.normal(0, tilt, 1)\n",
    "\n",
    "        print(f\"shift {shift_rnd}, tilt {tilt_rnd}  bias {bias_rnd}, res {res_rnd}\")\n",
    "        setup = Setup(dataset_input=dataset_asimov, rnd = True)\n",
    "        #setup.set_up_irf_sys(bias, resolution, norm, tilt)\n",
    "        dataset, dataset_N = setup.run()\n",
    "        # irf model\n",
    "        setup.set_irf_model(dataset_N)\n",
    "        if sys == \"Eff_area\":\n",
    "            dataset_N.models.parameters['resolution'].frozen = True\n",
    "            dataset_N.models.parameters['bias'].frozen = True\n",
    "            dataset_N.irf_model.parameters['tilt'].frozen = False\n",
    "            dataset_N.irf_model.parameters['norm'].frozen = False\n",
    "        setup.set_irf_prior(dataset_N, bias, resolution, norm, tilt)\n",
    "        fit_cor = Fit(store_trace=False)\n",
    "        result_cor = fit_cor.run([dataset])\n",
    "\n",
    "\n",
    "        stri = \"\"\n",
    "        parameters =  ['amplitude', 'index', 'lambda_', 'norm', 'tilt']\n",
    "        if \"crab_break\" in c['model']:\n",
    "            parameters =  ['amplitude', 'index1', 'index2', 'ebreak', 'beta', 'norm', 'tilt']\n",
    "        if \"crab_log\" in c['model']:\n",
    "            parameters =  ['amplitude', 'alpha', 'beta', 'norm', 'tilt']\n",
    "            \n",
    "        for p in parameters:\n",
    "            stri += str(dataset.models.parameters[p].value)  + '   ' +  str(dataset.models.parameters[p].error)  + '   '\n",
    "        stri += str(live) + \"  \"\n",
    "        print(stri)\n",
    "\n",
    "\n",
    "        fluxes = []\n",
    "        for e in ebins:\n",
    "            flux =  dataset.models[0].spectral_model(e)\n",
    "            fluxes.append(flux.value)\n",
    "\n",
    "        ff = str()\n",
    "        for f in fluxes:\n",
    "            ff += str(f) + \"  \"\n",
    "        #print(ff)\n",
    "\n",
    "        energy_bounds = (ebins[0], ebins[-1] ) * u.TeV\n",
    "\n",
    "        energy_min, energy_max = energy_bounds\n",
    "        energy = MapAxis.from_energy_bounds(\n",
    "            energy_min,\n",
    "            energy_max,\n",
    "            len(ebins),\n",
    "        )\n",
    "\n",
    "        fluxe2, _ = dataset.models[0].spectral_model._get_plot_flux(sed_type='dnde', energy=energy)\n",
    "        fluxe2 = scale_plot_flux(fluxe2, energy_power=2)\n",
    "        fluxe2 = fluxe2.quantity[:, 0, 0]\n",
    "        fluxe2 = np.array(fluxe2)   \n",
    "        ff2 = str()\n",
    "        for f in fluxe2:\n",
    "            ff2 += str(f) + \"  \"\n",
    "\n",
    "        energy_edges = dataset.geoms['geom'].axes[0].edges[::2]\n",
    "\n",
    "        fit_cor = Fit(store_trace=False)\n",
    "        #result_cor = fit_cor.run([dataset_N])\n",
    "\n",
    "        stri_N = \"\"\n",
    "        [parameters.append(p) for p in ['norm', 'tilt', 'bias', 'resolution']]\n",
    "        for p in parameters:\n",
    "            stri_N += str(dataset_N.models.parameters[p].value)  + '   ' +  str(dataset_N.models.parameters[p].error)  + '   '\n",
    "        stri_N += str(live) + \"  \"\n",
    "        print(stri_N)\n",
    "\n",
    "        fluxes = []\n",
    "        for e in ebins:\n",
    "            flux =  dataset_N.models[0].spectral_model(e)\n",
    "            fluxes.append(flux.value)\n",
    "\n",
    "        ffN = str()\n",
    "        for f in fluxes:\n",
    "            ffN += str(f) + \"  \"\n",
    "\n",
    "        energy_bounds = (ebins[0], ebins[-1] ) * u.TeV\n",
    "\n",
    "        energy_min, energy_max = energy_bounds\n",
    "        energy = MapAxis.from_energy_bounds(\n",
    "            energy_min,\n",
    "            energy_max,\n",
    "            len(ebins),\n",
    "        )\n",
    "\n",
    "        fluxe2, _ = dataset_N.models[0].spectral_model._get_plot_flux(sed_type='dnde', energy=energy)\n",
    "        fluxe2 = scale_plot_flux(fluxe2, energy_power=2)\n",
    "        fluxe2 = fluxe2.quantity[:, 0, 0]\n",
    "        fluxe2 = np.array(fluxe2)   \n",
    "        ffN2 = str()\n",
    "        for f in fluxe2:\n",
    "            ffN2 += str(f) + \"  \"\n",
    "\n",
    "        rnds = f\"{shift_rnd[0]:.6}_{tilt_rnd[0]:.6}_{bias_rnd[0]:.6}_{res_rnd[0]:.6}\"\n",
    "        if save_fluxpoints:\n",
    "            dataset.models.parameters['amplitude'].scan_n_sigma  = 5\n",
    "            dataset_N.models.parameters['amplitude'].scan_n_sigma  = 5\n",
    "            \n",
    "            esti  = FluxPointsEstimator(energy_edges= energy_edges, \n",
    "                                        selection_optional =  \"all\"\n",
    "                                       )\n",
    "            fluxpoints = esti.run([dataset])\n",
    "            # freeze all but IRF for fp and reopt = True\n",
    "            dataset_N.models[0].parameters.freeze_all()\n",
    "            dataset_N.models[0].parameters['amplitude'].frozen = False\n",
    "            dataset_N.background_model.parameters.freeze_all()\n",
    "            esti  = FluxPointsEstimator(energy_edges= energy_edges, selection_optional = None,\n",
    "                                       reoptimize=True)\n",
    "            fluxpoints_N = esti.run([dataset_N])\n",
    "            fluxpoints_N.write(f'{path}/data/fluxpoints/1P_fluxpoints_N_{live}_{rnds}.fits')\n",
    "            dataset_N.models.write(f'{path}/data/fluxpoints/1P_model_N_{live}_{rnds}.yaml')\n",
    "            fluxpoints.write(f'{path}/data/fluxpoints/1P_fluxpoints_{live}_{rnds}.fits')\n",
    "            dataset.models.write(f'{path}/data/fluxpoints/1P_model_{live}_{rnds}.yaml')\n",
    "        if contour:\n",
    "            computing_contour(dataset, rnds)\n",
    "            computing_contour(dataset_N, \"N\"+rnds)\n",
    "            \n",
    "            \n",
    "        save()\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        ep = 2\n",
    "        ax = dataset.models[0].spectral_model.plot((0.1,100)*u.TeV, color = 'tab:blue',\n",
    "                                                  label = \"without nui\",\n",
    "                                                  energy_power = ep)\n",
    "\n",
    "\n",
    "        dataset_asimov.models[0].spectral_model.plot((0.1,100)*u.TeV,ax = ax, color = 'black',\n",
    "                                                    energy_power = ep)\n",
    "\n",
    "        dataset_N.models[0].spectral_model.plot((0.1,100)*u.TeV,ax = ax, color = 'tab:orange',\n",
    "                                               label = \"with nui\",\n",
    "                                               energy_power = ep)\n",
    "        dataset_N.models[0].spectral_model.plot_error((0.1,100)*u.TeV,ax = ax, facecolor = 'tab:orange',\n",
    "                                                     energy_power = ep)\n",
    "        dataset.models[0].spectral_model.plot_error((0.1,100)*u.TeV,ax = ax, facecolor = 'tab:blue',\n",
    "                                                   energy_power = ep)\n",
    "\n",
    "        fluxpoints_N.plot(ax =ax,energy_power = ep )\n",
    "        fluxpoints.plot(ax =ax, energy_power = ep)\n",
    "        ax.legend(title = f\"live: {live} hr norm:{shift_rnd[0]:.3} tilt:{tilt_rnd[0]:.3}\")\n",
    "        fig = plt.gcf()\n",
    "        fig.savefig(f\"{path}/data/plots/{live}_{rnds}.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c67c84-f6f8-47a5-aa0a-4ea2b0d425e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

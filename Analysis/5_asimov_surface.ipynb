{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7853a11",
   "metadata": {},
   "source": [
    "## Runnning with gammapy-dev/IRF_model\n",
    "Fitting asimov datasets with nuisance parameters based on the different livetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04af29",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27bf135a-5ee4-4ca1-8549-6bf07929003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from gammapy.maps import Map\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from gammapy.modeling import Fit,  Parameters, Covariance , Parameter\n",
    "from gammapy.datasets import MapDataset ,Datasets, FluxPointsDataset\n",
    "from gammapy.modeling.models import (\n",
    "    PowerLawSpectralModel,\n",
    "    SkyModel,\n",
    "    PointSpatialModel,\n",
    "    PowerLawNormSpectralModel,\n",
    "    Models,\n",
    "    SpatialModel,\n",
    "    FoVBackgroundModel,\n",
    "    PiecewiseNormSpectralModel,\n",
    ")\n",
    "from gammapy.estimators import TSMapEstimator, ExcessMapEstimator\n",
    "from gammapy.estimators import FluxPoints, FluxPointsEstimator\n",
    "from scipy.interpolate import interp2d\n",
    "\n",
    "from regions import CircleSkyRegion, RectangleSkyRegion\n",
    "import yaml\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import Dataset_load \n",
    "\n",
    "from  Dataset_Setup import Setup, GaussianCovariance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de988df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eeeaf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Dataset_load.load_config()\n",
    "awo, aw, ewo, ew = c['_colors']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c45f4e-6432-405e-86b7-649e254c0950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.154434690031884\n"
     ]
    }
   ],
   "source": [
    "livetime = c['livetime']\n",
    "zero = c['zero'] \n",
    "norm = c['norm'] \n",
    "tilt = c['tilt'] \n",
    "bias = c['bias'] \n",
    "resolution = c['resolution'] \n",
    "magnitude = c['magnitude'] \n",
    "corrlength = c['corrlength']\n",
    "sys = c['sys'] \n",
    "folder = c['folder']\n",
    "nbidx = 0\n",
    "print(livetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94dc89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_input  = Dataset_load.create_asimov(model = c['model'], source = c['source'], \n",
    "                                               livetime = f\"{livetime}-hr\",\n",
    "                                        parameters = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0399d4",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b18ac-af52-48ac-bd1e-f03d21457fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "setup = Setup(dataset_input=dataset_input)\n",
    "#setup.set_up_irf_sys(bias, resolution, norm, tilt)\n",
    "dataset_asimov, dataset_asimov_N = setup.run()\n",
    "# irf model\n",
    "setup.set_irf_model(dataset_asimov_N)\n",
    "if sys == \"Eff_area\":\n",
    "    dataset_asimov_N.models.parameters['resolution'].frozen = True\n",
    "    dataset_asimov_N.irf_model.parameters['tilt'].frozen = False\n",
    "    dataset_asimov_N.irf_model.parameters['bias'].frozen = True\n",
    "    setup.set_irf_prior(dataset_asimov_N, bias, resolution, norm, tilt)\n",
    "    \n",
    "    \n",
    "if sys == \"E_reco\":\n",
    "    dataset_asimov_N.models.parameters['resolution'].frozen = True\n",
    "    dataset_asimov_N.irf_model.parameters['tilt'].frozen = True\n",
    "    dataset_asimov_N.irf_model.parameters['norm'].frozen = True\n",
    "    dataset_asimov_N.irf_model.parameters['bias'].frozen = False\n",
    "    setup.set_irf_prior(dataset_asimov_N, bias, resolution, norm, tilt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec637604-dbf7-4501-9012-2bf4c302d233",
   "metadata": {},
   "source": [
    "## Minos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031c52d-9f99-43ef-80aa-784a36f211e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_names = c['parameter_names']\n",
    "source = 'Crablog'\n",
    "scan_n_sigma = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6589e22-4b65-4ef2-a364-0fa01a829dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_surface(dataset, note, idx):\n",
    "        \n",
    "    fit_cor = Fit(store_trace=False)\n",
    "    #result_cor = fit_cor.run(dataset)\n",
    "    print(dataset_asimov.models[0])\n",
    "    \n",
    "    results = []\n",
    "    for parname1, parname2 in parameter_names[idx:idx+1] :\n",
    "        print( parname1, parname2)\n",
    "        dataset_asimov.models.parameters[parname1].scan_n_sigma  = scan_n_sigma  \n",
    "        dataset_asimov.models.parameters[parname2].scan_n_sigma  = scan_n_sigma    \n",
    "        if dataset_asimov.models.parameters[parname1].scan_min <0:\n",
    "            dataset_asimov.models.parameters[parname1].scan_min = 1e-15\n",
    "        if dataset_asimov.models.parameters[parname2].scan_min <0:\n",
    "            dataset_asimov.models.parameters[parname2].scan_min = 1e-15\n",
    "        result = fit_cor.stat_surface([dataset],\n",
    "                             dataset.models.parameters[parname1],\n",
    "                             dataset.models.parameters[parname2],\n",
    "                            reoptimize=True)\n",
    "        print(result)\n",
    "        contour_write = dict()\n",
    "        for k in result.keys():\n",
    "            print(k)\n",
    "            if k != \"fit_results\":\n",
    "                contour_write[k] =[float(_) for _ in np.array(result[k]).flatten()]#.tolist()\n",
    "\n",
    "        with open(f\"../{c['folder']}/data/3_surface_{note}_{parname1}_{parname2}_{scan_n_sigma}.yml\", \"w\") as outfile:\n",
    "        #with open(f\"../{c['folder']}/data/3_surface_{note}_{parname1}_{parname2}.yml\", \"w\") as outfile:\n",
    "            yaml.dump(contour_write, outfile, default_flow_style=False)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def read_in_surface(note):\n",
    "    results = []\n",
    "    for parname1, parname2 in parameter_names :\n",
    "        with open(f\"../{c['folder']}/data/3_surface_{note}_{parname1}_{parname2}_{scan_n_sigma}.yml\", \"r\") as stream:\n",
    "        #with open(f\"../{c['folder']}/data/3_surface_{note}_{parname1}_{parname2}.yml\", \"r\") as stream:\n",
    "            contour = yaml.safe_load(stream)\n",
    "        a = contour[f\"{source}.spectral.{parname1}_scan\"]\n",
    "        b = contour[f\"{source}.spectral.{parname2}_scan\"]\n",
    "        shape =len(a) , len(b)\n",
    "        contour['stat_scan'] = np.array(contour['stat_scan']).reshape(shape)\n",
    "        results.append(contour)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2201840-6c23-471d-b286-7152982bbb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "computing = 0\n",
    "if computing:\n",
    "    results = computing_surface(dataset_asimov, \"2.15h\", )\n",
    "else:\n",
    "    results = read_in_surface(\"2.15h\")\n",
    "    path = f'../{folder}/data/0_model_livetime_{livetime}.yml'\n",
    "    dataset_asimov.models = Models.read(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15504be3-41c3-4c1e-9590-65b48025ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "computing = 0\n",
    "if computing:\n",
    "    results_N = computing_surface(dataset_asimov_N, \"N_2.15h\", 0)\n",
    "    results_N = computing_surface(dataset_asimov_N, \"N_2.15h\", 1)\n",
    "    results_N = computing_surface(dataset_asimov_N, \"N_2.15h\", 2)\n",
    "else:\n",
    "    results_N = read_in_surface(\"N_2.15h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d0723-04c7-44b5-a5b4-aadeb0f1e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(Ls_new, x_new, y_new, threshold, find_min):\n",
    "    offset = Ls_new.min() + threshold\n",
    "    if offset > 0:\n",
    "        inside = Ls_new * (Ls_new < offset)\n",
    "    else:\n",
    "        inside = Ls_new * (Ls_new >= offset)\n",
    "    if find_min:  # find min:\n",
    "        pos = np.where(inside > 0)\n",
    "        ampli_best = x_new[np.where(Ls_new == Ls_new.min())[1][0]]\n",
    "        index_best = y_new[np.where(Ls_new == Ls_new.min())[0][0]]\n",
    "\n",
    "    else:  # find max\n",
    "        pos = np.where(inside > 0)\n",
    "        ampli_best = x_new[np.where(Ls_new == Ls_new.max())[1][0]]\n",
    "        index_best = y_new[np.where(Ls_new == Ls_new.max())[0][0]]\n",
    "\n",
    "    delta_bin = (x_new[1] - x_new[0]) / 2\n",
    "    ampli_min = x_new[np.min(pos[1])] - delta_bin\n",
    "    ampli_max = x_new[np.max(pos[1])] + delta_bin\n",
    "    ampli_best += delta_bin\n",
    "\n",
    "    delta_bin = (y_new[1] - y_new[0]) / 2\n",
    "    index_min = y_new[np.min(pos[0])] - delta_bin\n",
    "    index_max = y_new[np.max(pos[0])] + delta_bin\n",
    "    index_best += delta_bin\n",
    "\n",
    "    return index_min, index_max, ampli_min, ampli_max, index_best, ampli_best\n",
    "\n",
    "\n",
    "def plot_surface(contour, parname1, parname2,\n",
    "                source = \"Crabbreak\", note = \"\", plot_orig = True):\n",
    "    amplix__ = contour[f\"{source}.spectral.{parname1}_scan\"]\n",
    "    indexy__ = contour[f\"{source}.spectral.{parname2}_scan\"]\n",
    "    N_new = 110\n",
    "    N_new_y = 100\n",
    "    amplix__new = np.linspace(amplix__[0], amplix__[-1], N_new)\n",
    "    indexy__new = np.linspace(indexy__[0], indexy__[-1], N_new_y)\n",
    "    stat_scan = contour[\"stat_scan\"] - np.min(contour[\"stat_scan\"])\n",
    "\n",
    "    f = interp2d(\n",
    "        x=indexy__,\n",
    "        y=amplix__,\n",
    "        z=stat_scan,\n",
    "        kind=\"cubic\",\n",
    "        fill_value=None,\n",
    "        bounds_error=False,\n",
    "    )\n",
    "    data_contour = f(indexy__new, amplix__new)\n",
    "    \n",
    "    \n",
    "\n",
    "    dddd = np.array(contour[\"stat_scan\"])\n",
    "    ampli_best = amplix__[np.where(dddd == dddd.min())[0][0]]\n",
    "    index_best = indexy__[np.where(dddd == dddd.min())[1][0]]\n",
    "    if plot_orig:\n",
    "        fig, (ax1, ax) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        im = ax1.pcolormesh(indexy__, amplix__, stat_scan)\n",
    "        \n",
    "        ax1.plot(index_best, ampli_best, \"x\")\n",
    "        fig.colorbar(im, ax=ax1)\n",
    "        ax1.set_ylabel(parname1)\n",
    "        ax1.set_xlabel(parname2)\n",
    "        ax1.set_title(\"Likelihood\")\n",
    "        ax1.plot(dataset_input.models.parameters[parname2].value, \n",
    "                dataset_input.models.parameters[parname1].value,\n",
    "                \"+\", color = 'white')\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "    im = ax.pcolormesh(indexy__new, amplix__new, data_contour)\n",
    "    dddd = np.array(data_contour)\n",
    "    ampli_best = amplix__new[np.where(dddd == dddd.min())[0][0]]\n",
    "    index_best = indexy__new[np.where(dddd == dddd.min())[1][0]]\n",
    "    print(\"min index:\", index_best)\n",
    "    print(\"min amplitude:\", ampli_best)\n",
    "\n",
    "    ax.plot(index_best, ampli_best, \"x\")\n",
    "    ax.errorbar(dataset_input.models.parameters[parname2].value, \n",
    "            dataset_input.models.parameters[parname1].value,\n",
    "                xerr = dataset_input.models.parameters[parname2].error, \n",
    "                yerr = dataset_input.models.parameters[parname1].error, \n",
    "           fmt =  \"+\", color = 'white')\n",
    "    \n",
    "    fig.colorbar(im, ax=ax)\n",
    "    ax.set_ylabel(parname1)\n",
    "    ax.set_xlabel(parname2)\n",
    "    ax.set_title(\"Likelihood\")\n",
    "    \n",
    "    threshold_contour = 1\n",
    "\n",
    "    index_min, index_max, ampli_min, ampli_max, index_best, ampli_best  = compute_errors(\n",
    "        data_contour, indexy__new, amplix__new, threshold_contour, find_min=True\n",
    "    )\n",
    "    threshold = 1\n",
    "    CS = ax.contour(\n",
    "        indexy__new, amplix__new, data_contour,\n",
    "        colors=('white',), levels=[data_contour.min() + threshold]\n",
    "    )\n",
    "    return CS, fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d1e37-7d40-4fb1-8ca2-ee7ad46bf0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if c['model'] ==\"crab_log\":\n",
    "    source = \"Crablog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4fc9e-4399-460c-9b58-14087299ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSs, CS_Ns  = [] , []\n",
    "for i in range(len(parameter_names)):\n",
    "    CS, fig  = plot_surface(results[i], parameter_names[i][0], \n",
    "             parameter_names[i][1], source = source,plot_orig=1)\n",
    "    fig.savefig(f\"../{c['folder']}/plots/3_surface_{i}.pdf\")\n",
    "    CSs.append(CS)\n",
    "    \n",
    "    CS_N = plot_surface(results_N[i], parameter_names[i][0], \n",
    "             parameter_names[i][1], source = source,plot_orig=1)\n",
    "    \n",
    "    CS_Ns.append(CS_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbc8ca-6927-4452-8794-c24a803938df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2)\n",
    "axs = [axs[1][0], axs[1][1], axs[0][0]]\n",
    "for i, p in enumerate(parameter_names):\n",
    "    ax = axs[i]\n",
    "    dat = CSs[i].allsegs[0][0]\n",
    "    ax.plot(\n",
    "        dat[:, 0],\n",
    "        dat[:, 1],\n",
    "        color=awo[0],\n",
    "    )\n",
    "    \n",
    "    dat = CSs[i].allsegs[0][0]\n",
    "    ax.plot(\n",
    "        dat[:, 0],\n",
    "        dat[:, 1],\n",
    "        color=aw[0],\n",
    "    )\n",
    "    \n",
    "    ax.set_ylabel(p[0])\n",
    "    ax.set_xlabel(p[1])\n",
    "    p1 = dataset_asimov.models.parameters[p[0]]\n",
    "    p2 = dataset_asimov.models.parameters[p[1]]\n",
    "    ax.errorbar(p2.value, p1.value,  xerr = p2.error, \n",
    "               yerr = p1.error, color = awo[0])\n",
    "    p1 = dataset_asimov_N.models.parameters[p[0]]\n",
    "    p2 = dataset_asimov_N.models.parameters[p[1]]\n",
    "    ax.errorbar(p2.value, p1.value,  xerr = p2.error, \n",
    "               yerr = p1.error, color = aw[0])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4e0f5-1a09-4a30-ad87-9e5fc4ca2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = dataset_asimov.models[0].spectral_model.plot((0.1, 100)*u.TeV)\n",
    "dataset_asimov.models[0].spectral_model.plot_error((0.1, 100)*u.TeV, ax = ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb44530-6ccd-4554-9df3-56ce921f3c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f4f6f-9f73-4b47-bb74-c6a28f17f1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
